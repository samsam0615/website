import{T as C}from"./components.2315ec0e.js";import{_ as d,o as a,c as i,a as s,t as m,l as g,b as x,w as I,d as k,j as r,F as u,i as b,m as R,h}from"./entry.72050785.js";const A={name:"ResourceItem",props:{text:String},methods:{click(){this.$emit("click")},touchleave(){this.$emit("touchleave")}}};function w(n,o,p,v,e,t){return a(),i("div",{class:"resourceItem",onClick:o[0]||(o[0]=g((...c)=>t.click&&t.click(...c),["prevent"])),onTouchleave:o[1]||(o[1]=g((...c)=>t.touchleave&&t.touchleave(...c),["prevent"]))},[s("div",null,m(p.text),1)],32)}const L=d(A,[["render",w]]),y={name:"external",vision:[{imageURL:"",name:"CLIP Interrogator",url:"https://huggingface.co/spaces/pharma/CLIP-Interrogator",description:"CLIP Interrogator 分析用戶提供的圖像，並根據圖像內容提供相關的提示（Prompt）。用戶可以用以生成與原始圖像相似的圖像，或者根據提示進行進一步的修改和調整，從而生成符合自己需求的圖像"},{imageURL:"",name:"Craiyon",url:"https://www.craiyon.com/",description:"Craiyon 是一個免費的線上 AI 圖像生成工具，能夠在短時間內將簡單的文本提示（Prompt）轉換為圖像，即使你沒有繪圖天賦，只要不斷補充和調整文本提示，也可以創造出令人驚嘆的的圖像"},{imageURL:"",name:"Image to Music",url:"https://huggingface.co/spaces/fffiloni/img-to-music",description:"Image to Music 是一個以圖像生成音樂的工具，它先使用 CLIP Interrogator 將用戶提供的圖像轉化為提示（Prompt），再利用 Mubert Render（AI 免版稅音樂產生器）生成與圖像相關的音樂"},{imageUrl:"",name:"Quick Draw",url:"https://quickdraw.withgoogle.com/",description:"Quick, Draw! 是由 Google 開發的一款畫圖遊戲，玩家按照遊戲的提示繪畫圖形，而深度神經網絡會實時猜測圖形代表的內容。人工智能會透過每次遊戲會不斷學習，並提高未來的猜測能力。快來一起挑戰你的創造力和想像力吧！"},{imageURL:"",name:"Semi-Conductor",url:"https://semiconductor.withgoogle.com/",description:"Semi-Conductor 是一個姿勢偵測實驗，讓使用者透過攝像頭，擺出不同的姿勢以指揮自己的樂隊，例如改變音樂的節奏、音量和樂器。這個實驗提供了一個創新的互動體驗，讓用戶在音樂領域中發揮創意"},{imageURL:"",name:"Teachable Machine",url:"https://teachablemachine.withgoogle.com/",description:"Teachable Machine是由Google基於人工智能開發的網頁應用，可以幫助用戶快速地創建自己的機器學習模型。用戶只須簡單地輸入圖像、聲音或姿勢等數據，便可進行AI訓練，生成自己的機器學習模型。這個工具非常適合初學者和教育者使用，能夠幫助他們更加深入地了解機器學習技術的應用和原理"}],hear:[{imageURL:"",name:"Web Speech API",url:"https://www.google.com/intl/en/chrome/demos/speech.html ",description:"Web Speech API 可以讓用戶在網頁上使用自動語音識別和文本轉語音的功能。使用者可以透過麥克風輸入語音，Web Speech API 會將語音識別成文字，然後開發者可以將文字進行相應的處理，例如文本分析、關鍵字提取等等"}],speak:[{imageURL:"",name:"TTS Demo",url:"https://ttsdemo.com/ ",description:"TTS Demo 是一個文字轉語音合成系統，可以讓用戶選擇語言、聲音、音質和語調等參數，透過電腦語音合成將輸入的文字轉換成聲音輸出。 TTS Demo 可以應用於朗讀電子書、語音導航、語音提示等等"},{imageURL:"",name:"說唱合成",description:"說唱合成可以將輸入的文字配合選擇的的背景音樂、語速及語調轉換為說唱歌曲，生成的歌曲自然流暢、音色清晰而且節奏感強。使用者可以透過調整不同的音樂和語音設置，創作出符合自己口味的說唱歌曲",url:"https://www.volcengine.com/products/Rap-synthesis"}],read:[{imageURL:"",name:"Poe",url:"https://poe.com/ChatGPT",description:"Poe AI 是一款基於人工智能的聊天平台，它利用最先進的自然語言處理和機器學習技術，可以與用戶進行智能化的對話和交互。它可以理解並解釋用戶的自然語言輸入，並自動回答用戶的問題、提供建議、執行任務等"},{imageURL:"",name:"Semantris",url:"https://research.google.com/semantris",description:"Semantris 是一款使用機器學習的單詞聯想遊戲。當輸入一個詞語時，AI會檢查遊戲中的所有單詞，並選擇它認為最相關的單詞。由於AI接受過各種主題的對話文本訓練，因此它能夠根據詞義建立多種類型的關聯"},{imageURL:"",name:"詩人小冰",url:"https://poem.xiaoice.com/",description:"詩人小冰能夠根據用戶所提供的圖片和文字提示，生成不同長度的中文詩"}],create:[{name:"AI Duet",imageURL:"",url:"https://experiments.withgoogle.com/ai/ai-duet/view/",description:"AI Duet是一個互動音樂工具，它將人工智能技術應用於音樂創作和表演中。通過機器學習和即時音頻處理，使用者可以透過鍵盤、MIDI鍵盤或其他樂器與AI Duet互動，AI Duet會在即時計算後生成一段即興音樂回應。AI Duet是一個有趣的音樂教育工具，幫助音樂教育者向學生展示人工智能技術在音樂領域中的應用"},{imageURL:"",url:"https://huggingface.co/spaces/akhaliq/AnimeGANv2",name:"AnimeGAN v2",description:"AnimeGANv2 能夠將用家輸入的照片轉換為動畫風格"},{imageURL:"",name:"Blob Opera",description:"Blob Opera是一款由Google開發的基於人工智能的音樂互動工具，使用者通過滑鼠控制四個卡通Blob的高低音、音調和音量等屬性，即興創作和演唱自己的歌曲。透過機器學習技術和即時音頻處理，Blob Opera可以幫助音樂教育者向學生展示人工智能技術在音樂創作和教學中的應用",url:"https://artsandculture.google.com/experiment/blob-opera/AAHWrq360NcGbw?cp=e30"},{imageURL:"",name:"Image-to-Image Demo",description:"Image-to-Image 網站包括多個人工智能實驗，透過訓練圖像對（標籤與圖像），將用戶手繪的貓、建築物、手袋或鞋轉換成圖像",url:"https://affinelayer.com/pixsrv/"},{name:"Random Face Generator",url:"https://this-person-does-not-exist.com/en",imageURL:"",description:"Random Face Generator 是一個基於人工智能技術開發的人臉生成器，能夠隨機生成具有多種不同特徵和風格的人臉圖像。使用者可以透過調整多個參數，例如年齡、性別、種族、面部特徵等，生成符合自己需求的人臉圖像"},{name:"AnyTools",url:"https://anytools.pro/en/img/editor/styling",imageURL:"",description:"AnyTools.pro是一個基於人工智能的圖像和視頻風格遷移（Style Transfer）工具，能夠將一種圖像的風格應用到另一種圖像上，從而創造出新的藝術效果。它提供了多種預設的風格範本，同時也支援使用者上傳自定的風格範本。還可以對輸出結果進行微調和優化"}],advance:[{imageURL:"",name:"Keras.js",url:"https://transcranial.github.io/keras-js",description:"Keras 是一個開源神經網路庫。在Keras.js，用戶可以體驗不同AI實驗，例如手寫數字識別、圖像識別、超解析度成像等，從中學習不同深度神經網絡和工作原理"},{imageURL:"",name:"Tensorflow Playground",url:"http://playground.tensorflow.org",description:"在Tensorflow Playground 中，用戶可以透過調整深度神經網絡的層數、神經元數量、激勵函數、學習率等常見神經網絡訓練參數，觀察不同數值對AI識別器模型效果的影響"}]};const T={name:"Resource",data(){return{focus:null,focusClass:null,externalJson:null}},mounted(){const n=this;n.externalJson=y,n.focusClass=n.externalJson.vision,n.focus=n.focusClass[0]},methods:{setFocus(n){this.focus=n},setFocusClass(n){this.focusClass=this.externalJson[n]}}},U={class:"pageContent-container"},J={class:"text-container",onclick:""},P={class:"subTitle",ref:"resource"},D=s("br",null,null,-1),F=s("br",null,null,-1),S={class:"resourceContainer"},G={class:"resourceType"},B={class:"resourceSelector unselectable"},N={class:"resourceDescriptor"},M={class:"title"},j={class:"description",style:{"font-size":"16px","line-height":"24px"}},V={class:"media"},W=["href"];function q(n,o,p,v,e,t){const c=C,f=L;return a(),i(u,null,[x(c,null,{default:I(()=>[k("其他資源")]),_:1}),s("div",U,[s("div",J,[s("label",P,"其他資源",512),D,F,s("div",S,[s("div",G,[s("label",{class:r({active:e.externalJson!=null&&e.externalJson.vision==e.focusClass}),onClick:o[0]||(o[0]=l=>t.setFocusClass("vision"))},"視覺",2),s("label",{class:r({active:e.externalJson!=null&&e.externalJson.hear==e.focusClass}),onClick:o[1]||(o[1]=l=>t.setFocusClass("hear"))},"聽覺",2),s("label",{class:r({active:e.externalJson!=null&&e.externalJson.speak==e.focusClass}),onClick:o[2]||(o[2]=l=>t.setFocusClass("speak"))},"語音",2),s("label",{class:r({active:e.externalJson!=null&&e.externalJson.read==e.focusClass}),onClick:o[3]||(o[3]=l=>t.setFocusClass("read"))},"理解",2),s("label",{class:r({active:e.externalJson!=null&&e.externalJson.create==e.focusClass}),onClick:o[4]||(o[4]=l=>t.setFocusClass("create"))},"創作",2),s("label",{class:r({active:e.externalJson!=null&&e.externalJson.advance==e.focusClass}),onClick:o[5]||(o[5]=l=>t.setFocusClass("advance"))},"進階",2)]),s("div",B,[e.externalJson!=null?(a(!0),i(u,{key:0},b(e.focusClass,l=>(a(),R(f,{key:l.name,text:l.name,onClick:_=>t.setFocus(l),onTouchleave:_=>t.setFocus(l),class:r({active:e.focus==l})},null,8,["text","onClick","onTouchleave","class"]))),128)):h("",!0)]),s("div",N,[e.focus!=null?(a(),i(u,{key:0},[s("div",M,m(e.focus.name),1),s("div",j,m(e.focus.description),1),s("div",V,[s("a",{href:e.focus.url,target:"_blank"},"前往網站",8,W)])],64)):h("",!0)])])])])],64)}const z=d(T,[["render",q]]);export{z as default};
